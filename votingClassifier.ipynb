{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voting_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j88DnXGNSgcm"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier \n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score,recall_score,confusion_matrix\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Caz_rNfefw"
      },
      "source": [
        "ransom_test = pd.read_csv('/content/sample_data/files/ransom_dataset_test25samples.csv', nrows=25)\n",
        "benign_test = pd.read_csv('/content/sample_data/files/benign_dataset_test25samples.csv', nrows=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ME5iD5fhVR"
      },
      "source": [
        "ransom_test1 = ransom_test[ransom_test.columns[0:225000]]\n",
        "benign_test1 = benign_test[benign_test.columns[0:225000]]\n",
        "\n",
        "ransom_test2 = ransom_test[ransom_test.columns[0:175000]]\n",
        "benign_test2 = benign_test[benign_test.columns[0:175000]]\n",
        "\n",
        "ransom_test3 = ransom_test[ransom_test.columns[0:125000]]\n",
        "benign_test3 = benign_test[benign_test.columns[0:125000]]\n",
        "\n",
        "ransom_test4 = ransom_test[ransom_test.columns[0:75000]]\n",
        "benign_test4 = benign_test[benign_test.columns[0:75000]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4AMovBY0Qo7"
      },
      "source": [
        "ransom_test1['class']=1\n",
        "benign_test1['class']=0\n",
        "\n",
        "ransom_test2['class']=1\n",
        "benign_test2['class']=0\n",
        "\n",
        "ransom_test3['class']=1\n",
        "benign_test3['class']=0\n",
        "\n",
        "ransom_test4['class']=1\n",
        "benign_test4['class']=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri8aiLYc0ax2"
      },
      "source": [
        "test_df1 = pd.concat([ransom_test1,benign_test1],ignore_index=True)\n",
        "test_df1 = test_df1.fillna(0)\n",
        "\n",
        "test_df2 = pd.concat([ransom_test2,benign_test2],ignore_index=True)\n",
        "test_df2 = test_df2.fillna(0)\n",
        "\n",
        "test_df3 = pd.concat([ransom_test3,benign_test3],ignore_index=True)\n",
        "test_df3 = test_df3.fillna(0)\n",
        "\n",
        "test_df4 = pd.concat([ransom_test4,benign_test4],ignore_index=True)\n",
        "test_df4 = test_df4.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7VHGk1N0mOK"
      },
      "source": [
        "x_test1 = test_df1.drop('class',axis=1)\n",
        "\n",
        "\n",
        "x_test2 = test_df2.drop('class',axis=1)\n",
        "\n",
        "\n",
        "x_test3 = test_df3.drop('class',axis=1)\n",
        "\n",
        "\n",
        "x_test4 = test_df4.drop('class',axis=1)\n",
        "\n",
        "\n",
        "X_test=[x_test1,x_test2,x_test3,x_test4]\n",
        "Y_test=test_df4['class']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdJmEXmiSwyH"
      },
      "source": [
        "a=['saved_models/dt1.sav','saved_models/dt2.sav','saved_models/dt3.sav','saved_models/dt4.sav','saved_models/gb1.sav','saved_models/gb2.sav','saved_models/gb3.sav','saved_models/gb4.sav','saved_models/gnb1.sav','saved_models/gnb2.sav','saved_models/gnb3.sav','saved_models/gnb4.sav','saved_models/knn1.sav','saved_models/knn2.sav','saved_models/knn3.sav','saved_models/knn4.sav','saved_models/log1.sav','saved_models/log2.sav','saved_models/log3.sav','saved_models/log4.sav','saved_models/rf1.sav','saved_models/rf2.sav','saved_models/rf3.sav','saved_models/rf4.sav','saved_models/svm1.sav','saved_models/svm2.sav','saved_models/svm3.sav','saved_models/svm4.sav']\n",
        "l='/content/sample_data/'\n",
        "filenames=[]\n",
        "for i in a:\n",
        "  filenames.append(l+i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrfpbEF6XWUH"
      },
      "source": [
        "from itertools import chain, combinations\n",
        "\n",
        "def all_sublists(l):\n",
        "    return chain(*(combinations(l, i) for i in range(len(l) + 1)))\n",
        "\n",
        "def filtered_sublists(input_list, length):\n",
        "    return (\n",
        "        l for l in all_sublists(input_list)\n",
        "        if len(l) == length \n",
        "    )\n",
        "c=filtered_sublists(filenames,4)\n",
        "combinations=list(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC_AUVPvy-vB"
      },
      "source": [
        "len(combinations) #combinations of four models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS-WXGyIrbwZ"
      },
      "source": [
        "def predict(estimators,X_test):\n",
        "  predictions=np.asarray([est.predict(X) for est, X in zip(estimators, X_test)]).T\n",
        "  maj = np.apply_along_axis(lambda x: np.argmax(np.bincount(x,weights=None)),axis=1, arr=predictions)\n",
        "  return maj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSEXxedYLRF"
      },
      "source": [
        "\n",
        "with open('/content/sample_data/files/Voting4ModelsV2.csv','w') as f:\n",
        "  w=csv.writer(f)\n",
        "  w.writerow(['Models','Accuracy','Recall','Confusion Matrix'])\n",
        "  for c in range(9085,len(combinations)):\n",
        "    models=[pickle.load(open(i, 'rb')) for i in combinations[c]]\n",
        "    names=list(s.split('/')[4].split('.')[0] for s in combinations[c] )\n",
        "    datalist=list(int(x[-1])-1 for x in names)\n",
        "    testdata=[X_test[i] for i in datalist]\n",
        "    pred=predict(models,testdata)\n",
        "    acc=accuracy_score(Y_test,pred)\n",
        "    recall=recall_score(Y_test,pred)\n",
        "    conf=confusion_matrix(Y_test,pred)    \n",
        "    w.writerow([names.__str__()[1:-1].replace(\"'\",\"\"),acc,recall,conf.reshape(1,4).tolist().__str__()[2:-2]])\n",
        "    \n",
        "\n",
        "  \n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}